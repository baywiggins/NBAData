{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing required packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating LabelEncoder object for use within our main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating two sets to make sure we only include **active players** in the final CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/players.json\") as file:\n",
    "    players = json.load(file)\n",
    "\n",
    "active_players_name = set()\n",
    "active_players_code = set()\n",
    "\n",
    "for player in players.values():\n",
    "    active_players_name.add(player['Player'])\n",
    "    active_players_code.add(player['PlayerCode'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to update each row in our new dataframe with the defensive ratings (`opp_def_rtg` and `opp_def_rtg_adj`), as well as a function to make all the duplicate player codes the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2789': ['Larry Nance Jr.', 'Larry Nance'],\n",
       " '124084': ['Gary Payton', 'Gary Payton II'],\n",
       " '663874': ['Moe Wagner', 'Moritz Wagner'],\n",
       " '10014159': [\"Jae'sean Tate\", \"Jae'Sean Tate\"],\n",
       " '10012663': ['Isaiah Stewart', 'Isaiah Stewart II'],\n",
       " '10009546': ['Nathaniel Hinton', 'Nate Hinton'],\n",
       " '40722952': ['Herb Jones', 'Herbert Jones'],\n",
       " '47882246': ['Kenny Lofton', 'Kenneth Lofton'],\n",
       " '47267129': ['Vincent Williams', 'Vince Williams'],\n",
       " '47267136': ['MarJon Beauchamp', 'Marjon Beauchamp'],\n",
       " '40722937': ['BJ Boston', 'Brandon Boston'],\n",
       " '52566219': ['Dereck Lively', 'Dereck Lively II']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/id_to_player_mapping.json\", \"r\") as file:\n",
    "    player_dict = json.load(file)\n",
    "\n",
    "player_value_counts = {}\n",
    "for key, value in player_dict.items():\n",
    "    if value in player_value_counts:\n",
    "        player_value_counts[value].append(key)\n",
    "    else:\n",
    "        player_value_counts[value] = [key]\n",
    "\n",
    "duplicate_players = {value: keys for value, keys in player_value_counts.items() if len(keys) > 1}\n",
    "\n",
    "with open(\"data/player_to_id_mapping.json\", \"r\") as file:\n",
    "    id_dict = json.load(file)\n",
    "\n",
    "id_value_counts = {}\n",
    "for key, value in id_dict.items():\n",
    "    if value in id_value_counts:\n",
    "        id_value_counts[value].append(key)\n",
    "    else:\n",
    "        id_value_counts[value] = [key]\n",
    "\n",
    "duplicate_ids = {value: keys for value, keys in id_value_counts.items() if len(keys) > 1}\n",
    "\n",
    "with open('data/player_to_id_mapping.json', 'r') as file:\n",
    "    p_t_c = json.load(file)\n",
    "\n",
    "duplicate_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_def_ratings(row):\n",
    "    with open('data/def_rating.json', 'r') as file:\n",
    "        def_rtgs = json.load(file)\n",
    "    team_def_rtg = def_rtgs[row['Opponent'].upper()]\n",
    "    year = int(row['GameDay'].split(\"-\")[0])\n",
    "    for i in team_def_rtg:\n",
    "        if i['year'] == year:\n",
    "            return i['def_rtg'], i['def_rtg_adj']\n",
    "    \n",
    "    return -1, -1\n",
    "\n",
    "def standardize_player_id(row):\n",
    "    try:\n",
    "        return duplicate_ids[row['PlayerID']][0] if row['PlayerID'] in duplicate_ids else row['Player'], p_t_c[row['Player']]\n",
    "    except KeyError as e:\n",
    "        print(e, row[\"Player\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main function to generate and return a dataframe for each year specified, as well as player and team mappings for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataframe_by_year(year):\n",
    "    print(f\"Processing year: {year}\")\n",
    "    # Open the CSV file for the specific year and read its contents\n",
    "    with open(f\"data/NatStat-NBA{year}-Player_Statlines-2024-09-17-h13.csv\", \"r\") as file:\n",
    "        csv_content = file.read()\n",
    "\n",
    "    # Use StringIO to treat the CSV content as a file-like object for reading into pandas\n",
    "    data = StringIO(csv_content)\n",
    "\n",
    "    # Read the CSV into a pandas DataFrame, treating all columns as strings\n",
    "    df = pd.read_csv(data, dtype={\"GameDay\": \"string\", \"GameID\" : \"string\", \"Player\" : \"string\", \"PlayerID\" : \"string\", \n",
    "                                  \"PlayerCode\": \"string\", \"TeamID\" : \"string\", \"Team\" : \"string\", \"OpponentID\": \"string\", \n",
    "                                  \"Opponent\" : \"string\", \"Location\" : \"string\", \"Division\" : \"string\", \"Conference\" : \"string\", \n",
    "                                  \"Playoffs\" : \"string\", \"WinOrLoss\" : \"string\", \"Starter\" : \"string\", \"PlayerType\" : \"string\", \n",
    "                                  \"PerfScore\" : \"string\", \"MIN\" : \"string\", \"PTS\" : \"string\", \"FGM\" : \"string\", \"FGA\" : \"string\", \n",
    "                                  \"3FM\" : \"string\", \"3FA\" : \"string\", \"FTM\" : \"string\", \"FTA\" : \"string\", \"REB\" : \"string\", \n",
    "                                  \"AST\" : \"string\", \"STL\" : \"string\", \"BLK\" : \"string\", \"OREB\" : \"string\", \"TO\" : \"string\", \n",
    "                                  \"PF\" : \"string\"})\n",
    "    \n",
    "    if year < 2022:\n",
    "        df = df[~(df['Player'] == 'Jabari Smith')]\n",
    "\n",
    "    # Check if 'PlayerCode' exists, if not, create the column and fill it with 0 as in some years this column doesn't exist\n",
    "    if 'PlayerCode' not in df.columns:\n",
    "        df['PlayerCode'] = 0\n",
    "\n",
    "    # Apply the get_def_ratings function to get opponent defensive ratings and add them to the DataFrame\n",
    "    df[['opp_def_rtg', 'opp_def_rtg_adj']] = df.apply(get_def_ratings, axis=1, result_type=\"expand\")\n",
    "\n",
    "    # Filter the DataFrame to keep only active players based on PlayerCode or Player name\n",
    "    df = df[(df['PlayerCode'].isin(active_players_code)) | (df['Player'].isin(active_players_name))]\n",
    "\n",
    "    # Remove duplicate player IDs    \n",
    "    df[['Player', 'PlayerID']] = df.apply(standardize_player_id, axis=1, result_type=\"expand\")\n",
    "\n",
    "    # Create raw copy before performing more edits\n",
    "    df_raw = df.copy()\n",
    "\n",
    "    # Create dictionaries mapping PlayerID to Player name and TeamID to Team name\n",
    "    current_player_mappings = df.set_index('PlayerID')['Player'].to_dict()\n",
    "    current_team_mappings = df.set_index('TeamID')['Team'].to_dict()\n",
    "\n",
    "    # Drop unnecessary columns from the DataFrame\n",
    "    df.drop(columns=['GameDay', 'Player', 'PlayerCode', 'Team', 'Opponent', 'Division', 'Conference'], inplace=True)\n",
    "\n",
    "    # Fill missing values (NaNs) with '0'\n",
    "    df.fillna('0', inplace=True)\n",
    "\n",
    "    # Label encode categorical columns\n",
    "    df['Location'] = le.fit_transform(df['Location'])\n",
    "    df['Playoffs'] = le.fit_transform(df['Playoffs'])\n",
    "    df['WinOrLoss'] = le.fit_transform(df['WinOrLoss'])\n",
    "    df['Starter'] = le.fit_transform(df['Starter'])\n",
    "\n",
    "    # Convert all columns to numeric, replacing non-numeric values with 0\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "\n",
    "    # Print a message indicating the processing of the year is finished\n",
    "    print(f\"Finished year: {year}\")\n",
    "    \n",
    "    # Return the modified DataFrame and the current player and team mappings\n",
    "    return df, current_player_mappings, current_team_mappings, df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year: 2004\n",
      "Finished year: 2004\n",
      "Processing year: 2005\n",
      "Finished year: 2005\n",
      "Processing year: 2006\n",
      "Finished year: 2006\n",
      "Processing year: 2007\n",
      "Finished year: 2007\n",
      "Processing year: 2008\n",
      "Finished year: 2008\n",
      "Processing year: 2009\n",
      "Finished year: 2009\n",
      "Processing year: 2010\n",
      "Finished year: 2010\n",
      "Processing year: 2011\n",
      "Finished year: 2011\n",
      "Processing year: 2012\n",
      "Finished year: 2012\n",
      "Processing year: 2013\n",
      "Finished year: 2013\n",
      "Processing year: 2014\n",
      "Finished year: 2014\n",
      "Processing year: 2015\n",
      "Finished year: 2015\n",
      "Processing year: 2016\n",
      "Finished year: 2016\n",
      "Processing year: 2017\n",
      "Finished year: 2017\n",
      "Processing year: 2018\n",
      "Finished year: 2018\n",
      "Processing year: 2019\n",
      "Finished year: 2019\n",
      "Processing year: 2020\n",
      "Finished year: 2020\n",
      "Processing year: 2021\n",
      "Finished year: 2021\n",
      "Processing year: 2022\n",
      "Finished year: 2022\n",
      "Processing year: 2023\n",
      "Finished year: 2023\n",
      "Processing year: 2024\n",
      "Finished year: 2024\n"
     ]
    }
   ],
   "source": [
    "final = pd.DataFrame()\n",
    "final_raw = pd.DataFrame()\n",
    "player_mappings = {}\n",
    "team_mappings = {}\n",
    "years = [2000 + i for i in range(4, 25)]\n",
    "\n",
    "for year in years:\n",
    "    # Call function to get df and mappings\n",
    "    df, current_player_mappings, current_team_mappings, df_raw = generate_dataframe_by_year(year)\n",
    "    # Append the new df with our final one that we are going to save as CSV\n",
    "    final = pd.concat([final, df], ignore_index=True)\n",
    "    final_raw = pd.concat([final_raw, df_raw], ignore_index=True)\n",
    "    # Update the two mappings with (potentially) new values\n",
    "    player_mappings.update(current_player_mappings)\n",
    "    team_mappings.update(current_team_mappings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write our player and tean mappings to JSON files for later use, save the final csv for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"data/player_mappings.json\", \"w\") as file: \n",
    "#     json.dump(player_mappings, file)\n",
    "# with open(\"data/team_mappings.json\", \"w\") as file:\n",
    "#     json.dump(team_mappings, file)\n",
    "\n",
    "# Swap player and codes to create mapping\n",
    "# with open('data/id_to_player_mapping.json', 'r') as file:\n",
    "#     id_to_player_mapping = json.load(file)\n",
    "\n",
    "# player_to_id_mapping = {value: key for key, value in id_to_player_mapping.items()}\n",
    "\n",
    "# with open('data/player_to_id_mapping.json', 'w') as file:\n",
    "#     json.dump(player_to_id_mapping, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('data/out.csv', index=False)\n",
    "final_raw.to_csv('data/out_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for player in duplicate_players:\n",
    "    df = pd.concat([df, final_raw.query(f'Player == \"{player}\"')])\n",
    "\n",
    "df = df.drop_duplicates(subset=\"PlayerID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/out_raw.csv', 'r') as file:\n",
    "    raw_content = file.read()\n",
    "\n",
    "raw_data = StringIO(raw_content)\n",
    "final_raw = pd.read_csv(raw_data, dtype={\"GameDay\": \"string\", \"GameID\" : \"string\", \"Player\" : \"string\", \"PlayerID\" : \"string\", \n",
    "                                  \"PlayerCode\": \"string\", \"TeamID\" : \"string\", \"Team\" : \"string\", \"OpponentID\": \"string\", \n",
    "                                  \"Opponent\" : \"string\", \"Location\" : \"string\", \"Division\" : \"string\", \"Conference\" : \"string\", \n",
    "                                  \"Playoffs\" : \"string\", \"WinOrLoss\" : \"string\", \"Starter\" : \"string\", \"PlayerType\" : \"string\", \n",
    "                                  \"PerfScore\" : \"string\", \"MIN\" : \"string\", \"PTS\" : \"string\", \"FGM\" : \"string\", \"FGA\" : \"string\", \n",
    "                                  \"3FM\" : \"string\", \"3FA\" : \"string\", \"FTM\" : \"string\", \"FTA\" : \"string\", \"REB\" : \"string\", \n",
    "                                  \"AST\" : \"string\", \"STL\" : \"string\", \"BLK\" : \"string\", \"OREB\" : \"string\", \"TO\" : \"string\", \n",
    "                                  \"PF\" : \"string\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_by_year = {}\n",
    "unique_raw = final_raw.drop_duplicates(subset=\"Player\")\n",
    "\n",
    "for year in range(2003, 2025):\n",
    "    if year not in players_by_year:\n",
    "        players_by_year[year] = []\n",
    "\n",
    "    pd = unique_raw.query(f'GameDay > \"{year}-1-8\" & GameDay < \"{year + 1}-7-1\"')['Player'].to_dict()\n",
    "    for name in pd.items():\n",
    "        players_by_year[year].append(name[1])\n",
    "\n",
    "with open('data/players_by_year.json', 'w') as file:\n",
    "    json.dump(players_by_year, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
